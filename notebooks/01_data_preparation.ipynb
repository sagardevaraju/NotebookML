{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Clean and stage the Titanic dataset for downstream modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is parameterised by Papermill and supports pandas, Modin on Ray, and Dask dataframe engines through the shared [`BackendManager`](../notebookml/backends.py).\n",
    "The default dataset is the classic Kaggle Titanic competition data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'engine': 'pandas',\n",
    "    'modin_engine': 'ray',\n",
    "    'dataset_url': 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv',\n",
    "    'output_path': 'data/processed.csv',\n",
    "    'summary_path': 'data/data_prep_summary.json'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from notebookml import BackendManager\n",
    "\n",
    "engine = params.get('engine', 'pandas')\n",
    "modin_engine = params.get('modin_engine', 'ray')\n",
    "dataset_url = params['dataset_url']\n",
    "output_path = Path(params['output_path'])\n",
    "summary_path = Path(params['summary_path'])\n",
    "\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "summary_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "backend = BackendManager(engine=engine, modin_engine=modin_engine)\n",
    "df = backend.read_csv(dataset_url)\n",
    "pdf = backend.to_pandas(df)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Basic cleaning\n",
    "pdf = pdf.drop_duplicates()\n",
    "\n",
    "numeric_cols = [col for col in pdf.select_dtypes(include=['number']).columns if col != 'Survived']\n",
    "if numeric_cols:\n",
    "    medians = pdf[numeric_cols].median()\n",
    "    pdf[numeric_cols] = pdf[numeric_cols].fillna(medians)\n",
    "\n",
    "categorical_cols = [\n",
    "    col\n",
    "    for col in pdf.select_dtypes(include=['object', 'category']).columns\n",
    "    if col not in {'Ticket', 'Name'}\n",
    "]\n",
    "if categorical_cols:\n",
    "    modes = pdf[categorical_cols].mode(dropna=True).iloc[0]\n",
    "    pdf[categorical_cols] = pdf[categorical_cols].fillna(modes)\n",
    "\n",
    "pdf['CabinKnown'] = pdf['Cabin'].notnull().astype(int)\n",
    "pdf['FamilySize'] = pdf['SibSp'] + pdf['Parch'] + 1\n",
    "\n",
    "# Convert back to the requested backend before saving.\n",
    "if engine == 'dask':\n",
    "    df_clean = backend.frame_namespace.from_pandas(pdf, npartitions=1)\n",
    "elif engine == 'modin':\n",
    "    df_clean = backend.frame_namespace.DataFrame(pdf)\n",
    "else:\n",
    "    df_clean = pdf\n",
    "\n",
    "backend.to_csv(df_clean, str(output_path), index=False)\n",
    "\n",
    "summary = {\n",
    "    'engine': engine,\n",
    "    'rows': int(pdf.shape[0]),\n",
    "    'columns': pdf.columns.tolist(),\n",
    "}\n",
    "\n",
    "with summary_path.open('w') as fp:\n",
    "    json.dump(summary, fp, indent=2)\n",
    "\n",
    "backend.close()\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}