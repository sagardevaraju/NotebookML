{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Transform the cleaned dataset into model-ready features and persist train/test splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook expects the output of the Data Preparation step and applies deterministic feature transformations that are compatible across pandas, Modin, and Dask backends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'engine': 'pandas',\n",
    "    'modin_engine': 'ray',\n",
    "    'input_path': 'data/processed.csv',\n",
    "    'train_output_path': 'data/train_features.csv',\n",
    "    'test_output_path': 'data/test_features.csv',\n",
    "    'feature_metadata_path': 'data/feature_metadata.json',\n",
    "    'target_column': 'Survived',\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 42\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from notebookml import BackendManager\n",
    "\n",
    "engine = params.get('engine', 'pandas')\n",
    "modin_engine = params.get('modin_engine', 'ray')\n",
    "input_path = Path(params['input_path'])\n",
    "train_output_path = Path(params['train_output_path'])\n",
    "test_output_path = Path(params['test_output_path'])\n",
    "metadata_path = Path(params['feature_metadata_path'])\n",
    "target_column = params['target_column']\n",
    "test_size = float(params.get('test_size', 0.2))\n",
    "random_state = int(params.get('random_state', 42))\n",
    "\n",
    "train_output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "test_output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "metadata_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "backend = BackendManager(engine=engine, modin_engine=modin_engine)\n",
    "df = backend.read_csv(str(input_path))\n",
    "pdf = backend.to_pandas(df)\n",
    "\n",
    "pdf['Title'] = (\n",
    "    pdf['Name'].str.extract(r',\\s*([^\\.]+)\\.', expand=False).fillna('Unknown')\n",
    ")\n",
    "pdf['IsAlone'] = (pdf['FamilySize'] == 1).astype(int)\n",
    "pdf['FarePerPerson'] = pdf['Fare'] / pdf['FamilySize'].clip(lower=1)\n",
    "\n",
    "drop_columns = ['Name', 'Ticket', 'Cabin']\n",
    "feature_df = pdf.drop(columns=[col for col in drop_columns if col in pdf.columns])\n",
    "categorical_cols = [col for col in ['Sex', 'Embarked', 'Title'] if col in feature_df.columns]\n",
    "\n",
    "target_series = feature_df[target_column]\n",
    "feature_df = feature_df.drop(columns=[target_column])\n",
    "feature_df = feature_df.fillna(0)\n",
    "feature_df = pd.get_dummies(feature_df, columns=categorical_cols, drop_first=True)\n",
    "feature_df[target_column] = target_series\n",
    "\n",
    "X = feature_df.drop(columns=[target_column])\n",
    "y = feature_df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df[target_column] = y_train\n",
    "test_df = X_test.copy()\n",
    "test_df[target_column] = y_test\n",
    "\n",
    "if engine == 'dask':\n",
    "    train_backend = backend.frame_namespace.from_pandas(train_df, npartitions=1)\n",
    "    test_backend = backend.frame_namespace.from_pandas(test_df, npartitions=1)\n",
    "elif engine == 'modin':\n",
    "    train_backend = backend.frame_namespace.DataFrame(train_df)\n",
    "    test_backend = backend.frame_namespace.DataFrame(test_df)\n",
    "else:\n",
    "    train_backend = train_df\n",
    "    test_backend = test_df\n",
    "\n",
    "backend.to_csv(train_backend, str(train_output_path), index=False)\n",
    "backend.to_csv(test_backend, str(test_output_path), index=False)\n",
    "\n",
    "metadata = {\n",
    "    'engine': engine,\n",
    "    'target_column': target_column,\n",
    "    'feature_columns': X_train.columns.tolist(),\n",
    "    'categorical_columns': categorical_cols,\n",
    "    'test_size': test_size,\n",
    "    'random_state': random_state,\n",
    "}\n",
    "\n",
    "with metadata_path.open('w') as fp:\n",
    "    json.dump(metadata, fp, indent=2)\n",
    "\n",
    "backend.close()\n",
    "metadata\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}